{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This example looks at the Kaggle Credit Card Fraud Detection dataset to demonstrate how to train a classification model on data with highly imbalanced classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEADER: \"Time\",\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\",\"V7\",\"V8\",\"V9\",\"V10\",\"V11\",\"V12\",\"V13\",\"V14\",\"V15\",\"V16\",\"V17\",\"V18\",\"V19\",\"V20\",\"V21\",\"V22\",\"V23\",\"V24\",\"V25\",\"V26\",\"V27\",\"V28\",\"Amount\",\"Class\"\n",
      "EXAMPLE FEATURES: [0.0, -1.3598071336738, -0.0727811733098497, 2.53634673796914, 1.37815522427443, -0.338320769942518, 0.462387777762292, 0.239598554061257, 0.0986979012610507, 0.363786969611213, 0.0907941719789316, -0.551599533260813, -0.617800855762348, -0.991389847235408, -0.311169353699879, 1.46817697209427, -0.470400525259478, 0.207971241929242, 0.0257905801985591, 0.403992960255733, 0.251412098239705, -0.018306777944153, 0.277837575558899, -0.110473910188767, 0.0669280749146731, 0.128539358273528, -0.189114843888824, 0.133558376740387, -0.0210530534538215, 149.62]\n",
      "features.shape: (284807, 30)\n",
      "targets.shape: (284807, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "# Get the real data from https://www.kaggle.com/mlg-ulb/creditcardfraud/\n",
    "fname = \"../data/imbalanced-classification/creditcard.csv\"\n",
    "\n",
    "all_features = []\n",
    "all_targets = []\n",
    "with open(fname) as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i == 0:\n",
    "            print(\"HEADER:\", line.strip())\n",
    "            continue # skip header\n",
    "        fields = line.strip().split(\",\")\n",
    "        all_features.append([float(v.replace('\"', \"\")) for v in fields[:-1]])\n",
    "        all_targets.append([int(fields[-1].replace('\"', \"\"))])\n",
    "        if i == 1:\n",
    "            print(\"EXAMPLE FEATURES:\", all_features[-1])\n",
    "features = np.array(all_features, dtype=\"float32\")\n",
    "targets = np.array(all_targets, dtype=\"uint8\")\n",
    "print(\"features.shape:\", features.shape)\n",
    "print(\"targets.shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 227846\n",
      "Number of validation samples: 56961\n"
     ]
    }
   ],
   "source": [
    "num_val_samples = int(len(features) * 0.2)\n",
    "train_features = features[:-num_val_samples]\n",
    "train_targets = targets[:-num_val_samples]\n",
    "val_features = features[-num_val_samples:]\n",
    "val_targets = targets[-num_val_samples:]\n",
    "\n",
    "print(\"Number of training samples:\", len(train_features))\n",
    "print(\"Number of validation samples:\", len(val_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze class imbalance in the targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of count for class 0: 227429\n",
      "# of count for class 1: 417\n"
     ]
    }
   ],
   "source": [
    "counts = np.bincount(train_targets[:, 0])\n",
    "for i, count in enumerate(counts):\n",
    "    print(\"# of count for class {}: {}\".format(i, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive samples in training data: 417 (0.18% of total)\n",
      "weight for class 0: 4.396976638863118e-06\n",
      "weight for class 1: 0.002398081534772182\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Number of positive samples in training data: {} ({:.2f}% of total)\".format(\n",
    "        counts[1], 100 * float(counts[1]) / len(train_targets)\n",
    "    )\n",
    ")\n",
    "\n",
    "weight_for_0 = 1.0 / counts[0]\n",
    "weight_for_1 = 1.0 / counts[1]\n",
    "\n",
    "print(\"weight for class 0: {}\".format(weight_for_0))\n",
    "print(\"weight for class 1: {}\".format(weight_for_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize the data using ***training*** set statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(train_features, axis=0)\n",
    "train_features -= mean\n",
    "val_features -= mean\n",
    "std = np.std(train_features, axis=0)\n",
    "train_features /= std\n",
    "val_features /= std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a binary classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 256)               7936      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 139,777\n",
      "Trainable params: 139,777\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "l = keras.layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    l.Dense(256, activation='relu', input_shape=(train_features.shape[-1],)),\n",
    "    l.Dense(256, activation='relu'),\n",
    "    l.Dropout(0.3),\n",
    "    l.Dense(256, activation='relu'),\n",
    "    l.Dropout(0.3),\n",
    "    l.Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model with `class_weight` argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "112/112 - 1s - loss: 2.2907e-07 - fn: 2.0000 - fp: 2718.0000 - tn: 224711.0000 - tp: 415.0000 - precision: 0.1325 - recall: 0.9952 - val_loss: 0.0133 - val_fn: 11.0000 - val_fp: 306.0000 - val_tn: 56580.0000 - val_tp: 64.0000 - val_precision: 0.1730 - val_recall: 0.8533\n",
      "Epoch 2/30\n",
      "112/112 - 0s - loss: 2.5064e-07 - fn: 5.0000 - fp: 2286.0000 - tn: 225143.0000 - tp: 412.0000 - precision: 0.1527 - recall: 0.9880 - val_loss: 0.0137 - val_fn: 13.0000 - val_fp: 195.0000 - val_tn: 56691.0000 - val_tp: 62.0000 - val_precision: 0.2412 - val_recall: 0.8267\n",
      "Epoch 3/30\n",
      "112/112 - 0s - loss: 1.5674e-07 - fn: 1.0000 - fp: 1657.0000 - tn: 225772.0000 - tp: 416.0000 - precision: 0.2007 - recall: 0.9976 - val_loss: 0.0138 - val_fn: 13.0000 - val_fp: 278.0000 - val_tn: 56608.0000 - val_tp: 62.0000 - val_precision: 0.1824 - val_recall: 0.8267\n",
      "Epoch 4/30\n",
      "112/112 - 0s - loss: 2.8296e-07 - fn: 1.0000 - fp: 1956.0000 - tn: 225473.0000 - tp: 416.0000 - precision: 0.1754 - recall: 0.9976 - val_loss: 0.0386 - val_fn: 10.0000 - val_fp: 729.0000 - val_tn: 56157.0000 - val_tp: 65.0000 - val_precision: 0.0819 - val_recall: 0.8667\n",
      "Epoch 5/30\n",
      "112/112 - 0s - loss: 2.1401e-07 - fn: 1.0000 - fp: 2189.0000 - tn: 225240.0000 - tp: 416.0000 - precision: 0.1597 - recall: 0.9976 - val_loss: 0.0163 - val_fn: 13.0000 - val_fp: 222.0000 - val_tn: 56664.0000 - val_tp: 62.0000 - val_precision: 0.2183 - val_recall: 0.8267\n",
      "Epoch 6/30\n",
      "112/112 - 0s - loss: 6.2920e-07 - fn: 5.0000 - fp: 3574.0000 - tn: 223855.0000 - tp: 412.0000 - precision: 0.1034 - recall: 0.9880 - val_loss: 0.0394 - val_fn: 10.0000 - val_fp: 898.0000 - val_tn: 55988.0000 - val_tp: 65.0000 - val_precision: 0.0675 - val_recall: 0.8667\n",
      "Epoch 7/30\n",
      "112/112 - 0s - loss: 3.3098e-07 - fn: 1.0000 - fp: 4067.0000 - tn: 223362.0000 - tp: 416.0000 - precision: 0.0928 - recall: 0.9976 - val_loss: 0.0185 - val_fn: 12.0000 - val_fp: 373.0000 - val_tn: 56513.0000 - val_tp: 63.0000 - val_precision: 0.1445 - val_recall: 0.8400\n",
      "Epoch 8/30\n",
      "112/112 - 0s - loss: 2.4520e-07 - fn: 2.0000 - fp: 2889.0000 - tn: 224540.0000 - tp: 415.0000 - precision: 0.1256 - recall: 0.9952 - val_loss: 0.0184 - val_fn: 12.0000 - val_fp: 347.0000 - val_tn: 56539.0000 - val_tp: 63.0000 - val_precision: 0.1537 - val_recall: 0.8400\n",
      "Epoch 9/30\n",
      "112/112 - 0s - loss: 4.2991e-07 - fn: 3.0000 - fp: 3801.0000 - tn: 223628.0000 - tp: 414.0000 - precision: 0.0982 - recall: 0.9928 - val_loss: 0.0147 - val_fn: 10.0000 - val_fp: 329.0000 - val_tn: 56557.0000 - val_tp: 65.0000 - val_precision: 0.1650 - val_recall: 0.8667\n",
      "Epoch 10/30\n",
      "112/112 - 0s - loss: 1.7536e-07 - fn: 0.0000e+00 - fp: 1915.0000 - tn: 225514.0000 - tp: 417.0000 - precision: 0.1788 - recall: 1.0000 - val_loss: 0.0175 - val_fn: 11.0000 - val_fp: 315.0000 - val_tn: 56571.0000 - val_tp: 64.0000 - val_precision: 0.1689 - val_recall: 0.8533\n",
      "Epoch 11/30\n",
      "112/112 - 0s - loss: 2.0318e-07 - fn: 2.0000 - fp: 2405.0000 - tn: 225024.0000 - tp: 415.0000 - precision: 0.1472 - recall: 0.9952 - val_loss: 0.0219 - val_fn: 10.0000 - val_fp: 590.0000 - val_tn: 56296.0000 - val_tp: 65.0000 - val_precision: 0.0992 - val_recall: 0.8667\n",
      "Epoch 12/30\n",
      "112/112 - 0s - loss: 3.0920e-07 - fn: 2.0000 - fp: 2492.0000 - tn: 224937.0000 - tp: 415.0000 - precision: 0.1428 - recall: 0.9952 - val_loss: 0.0126 - val_fn: 12.0000 - val_fp: 257.0000 - val_tn: 56629.0000 - val_tp: 63.0000 - val_precision: 0.1969 - val_recall: 0.8400\n",
      "Epoch 13/30\n",
      "112/112 - 0s - loss: 5.4667e-07 - fn: 3.0000 - fp: 3036.0000 - tn: 224393.0000 - tp: 414.0000 - precision: 0.1200 - recall: 0.9928 - val_loss: 0.0401 - val_fn: 13.0000 - val_fp: 157.0000 - val_tn: 56729.0000 - val_tp: 62.0000 - val_precision: 0.2831 - val_recall: 0.8267\n",
      "Epoch 14/30\n",
      "112/112 - 0s - loss: 2.2584e-06 - fn: 5.0000 - fp: 2735.0000 - tn: 224694.0000 - tp: 412.0000 - precision: 0.1309 - recall: 0.9880 - val_loss: 0.0291 - val_fn: 12.0000 - val_fp: 152.0000 - val_tn: 56734.0000 - val_tp: 63.0000 - val_precision: 0.2930 - val_recall: 0.8400\n",
      "Epoch 15/30\n",
      "112/112 - 0s - loss: 1.6642e-06 - fn: 2.0000 - fp: 1697.0000 - tn: 225732.0000 - tp: 415.0000 - precision: 0.1965 - recall: 0.9952 - val_loss: 0.0453 - val_fn: 14.0000 - val_fp: 134.0000 - val_tn: 56752.0000 - val_tp: 61.0000 - val_precision: 0.3128 - val_recall: 0.8133\n",
      "Epoch 16/30\n",
      "112/112 - 0s - loss: 1.3676e-06 - fn: 1.0000 - fp: 1133.0000 - tn: 226296.0000 - tp: 416.0000 - precision: 0.2686 - recall: 0.9976 - val_loss: 0.0336 - val_fn: 12.0000 - val_fp: 240.0000 - val_tn: 56646.0000 - val_tp: 63.0000 - val_precision: 0.2079 - val_recall: 0.8400\n",
      "Epoch 17/30\n",
      "112/112 - 0s - loss: 1.4884e-06 - fn: 5.0000 - fp: 1406.0000 - tn: 226023.0000 - tp: 412.0000 - precision: 0.2266 - recall: 0.9880 - val_loss: 0.0736 - val_fn: 9.0000 - val_fp: 1042.0000 - val_tn: 55844.0000 - val_tp: 66.0000 - val_precision: 0.0596 - val_recall: 0.8800\n",
      "Epoch 18/30\n",
      "112/112 - 0s - loss: 2.6387e-06 - fn: 6.0000 - fp: 3170.0000 - tn: 224259.0000 - tp: 411.0000 - precision: 0.1148 - recall: 0.9856 - val_loss: 0.0530 - val_fn: 7.0000 - val_fp: 846.0000 - val_tn: 56040.0000 - val_tp: 68.0000 - val_precision: 0.0744 - val_recall: 0.9067\n",
      "Epoch 19/30\n",
      "112/112 - 0s - loss: 7.7947e-07 - fn: 8.0000 - fp: 5768.0000 - tn: 221661.0000 - tp: 409.0000 - precision: 0.0662 - recall: 0.9808 - val_loss: 0.0183 - val_fn: 12.0000 - val_fp: 374.0000 - val_tn: 56512.0000 - val_tp: 63.0000 - val_precision: 0.1442 - val_recall: 0.8400\n",
      "Epoch 20/30\n",
      "112/112 - 0s - loss: 4.2781e-07 - fn: 4.0000 - fp: 2451.0000 - tn: 224978.0000 - tp: 413.0000 - precision: 0.1442 - recall: 0.9904 - val_loss: 0.0478 - val_fn: 9.0000 - val_fp: 920.0000 - val_tn: 55966.0000 - val_tp: 66.0000 - val_precision: 0.0669 - val_recall: 0.8800\n",
      "Epoch 21/30\n",
      "112/112 - 0s - loss: 1.0194e-06 - fn: 6.0000 - fp: 3492.0000 - tn: 223937.0000 - tp: 411.0000 - precision: 0.1053 - recall: 0.9856 - val_loss: 0.0665 - val_fn: 9.0000 - val_fp: 485.0000 - val_tn: 56401.0000 - val_tp: 66.0000 - val_precision: 0.1198 - val_recall: 0.8800\n",
      "Epoch 22/30\n",
      "112/112 - 0s - loss: 2.0753e-07 - fn: 2.0000 - fp: 1732.0000 - tn: 225697.0000 - tp: 415.0000 - precision: 0.1933 - recall: 0.9952 - val_loss: 0.0177 - val_fn: 10.0000 - val_fp: 348.0000 - val_tn: 56538.0000 - val_tp: 65.0000 - val_precision: 0.1574 - val_recall: 0.8667\n",
      "Epoch 23/30\n",
      "112/112 - 0s - loss: 1.3653e-07 - fn: 0.0000e+00 - fp: 1542.0000 - tn: 225887.0000 - tp: 417.0000 - precision: 0.2129 - recall: 1.0000 - val_loss: 0.0111 - val_fn: 13.0000 - val_fp: 171.0000 - val_tn: 56715.0000 - val_tp: 62.0000 - val_precision: 0.2661 - val_recall: 0.8267\n",
      "Epoch 24/30\n",
      "112/112 - 0s - loss: 1.8929e-07 - fn: 1.0000 - fp: 1811.0000 - tn: 225618.0000 - tp: 416.0000 - precision: 0.1868 - recall: 0.9976 - val_loss: 0.0105 - val_fn: 13.0000 - val_fp: 207.0000 - val_tn: 56679.0000 - val_tp: 62.0000 - val_precision: 0.2305 - val_recall: 0.8267\n",
      "Epoch 25/30\n",
      "112/112 - 0s - loss: 2.5351e-07 - fn: 2.0000 - fp: 2156.0000 - tn: 225273.0000 - tp: 415.0000 - precision: 0.1614 - recall: 0.9952 - val_loss: 0.0162 - val_fn: 11.0000 - val_fp: 370.0000 - val_tn: 56516.0000 - val_tp: 64.0000 - val_precision: 0.1475 - val_recall: 0.8533\n",
      "Epoch 26/30\n",
      "112/112 - 0s - loss: 1.7377e-07 - fn: 1.0000 - fp: 1956.0000 - tn: 225473.0000 - tp: 416.0000 - precision: 0.1754 - recall: 0.9976 - val_loss: 0.0139 - val_fn: 12.0000 - val_fp: 285.0000 - val_tn: 56601.0000 - val_tp: 63.0000 - val_precision: 0.1810 - val_recall: 0.8400\n",
      "Epoch 27/30\n",
      "112/112 - 0s - loss: 1.6577e-07 - fn: 1.0000 - fp: 1520.0000 - tn: 225909.0000 - tp: 416.0000 - precision: 0.2149 - recall: 0.9976 - val_loss: 0.0207 - val_fn: 11.0000 - val_fp: 215.0000 - val_tn: 56671.0000 - val_tp: 64.0000 - val_precision: 0.2294 - val_recall: 0.8533\n",
      "Epoch 28/30\n",
      "112/112 - 0s - loss: 1.8185e-07 - fn: 0.0000e+00 - fp: 944.0000 - tn: 226485.0000 - tp: 417.0000 - precision: 0.3064 - recall: 1.0000 - val_loss: 0.0155 - val_fn: 10.0000 - val_fp: 229.0000 - val_tn: 56657.0000 - val_tp: 65.0000 - val_precision: 0.2211 - val_recall: 0.8667\n",
      "Epoch 29/30\n",
      "112/112 - 0s - loss: 2.3454e-07 - fn: 1.0000 - fp: 1647.0000 - tn: 225782.0000 - tp: 416.0000 - precision: 0.2016 - recall: 0.9976 - val_loss: 0.0334 - val_fn: 8.0000 - val_fp: 561.0000 - val_tn: 56325.0000 - val_tp: 67.0000 - val_precision: 0.1067 - val_recall: 0.8933\n",
      "Epoch 30/30\n",
      "112/112 - 0s - loss: 3.3241e-07 - fn: 5.0000 - fp: 3255.0000 - tn: 224174.0000 - tp: 412.0000 - precision: 0.1124 - recall: 0.9880 - val_loss: 0.0175 - val_fn: 9.0000 - val_fp: 284.0000 - val_tn: 56602.0000 - val_tp: 66.0000 - val_precision: 0.1886 - val_recall: 0.8800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe1c0578e90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = keras.metrics\n",
    "\n",
    "metrics = [\n",
    "    m.FalseNegatives(name='fn'),\n",
    "    m.FalsePositives(name='fp'),\n",
    "    m.TrueNegatives(name='tn'),\n",
    "    m.TruePositives(name='tp'),\n",
    "    m.Precision(name='precision'),\n",
    "    m.Recall(name='recall'),\n",
    "]\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(1e-2),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=metrics)\n",
    "\n",
    "callbacks = [keras.callbacks.ModelCheckpoint(\"../checkpoints/imbalanced-classification/fraud_model_at_epoch_{epoch}.h5\")]\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "model.fit(\n",
    "    train_features,\n",
    "    train_targets,\n",
    "    batch_size=2048,\n",
    "    epochs=30,\n",
    "    verbose=2,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=(val_features, val_targets),\n",
    "    class_weight=class_weight,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "At the end of training, out of 56,961 validation transactions, we are:\n",
    "\n",
    "Correctly identifying 66 of them as fraudulent\n",
    "Missing 9 fraudulent transactions\n",
    "At the cost of incorrectly flagging 284 legitimate transactions\n",
    "In the real world, one would put an even higher weight on class 1, so as to reflect that False Negatives are more costly than False Positives.\n",
    "\n",
    "Next time your credit card gets declined in an online purchase -- this is why."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
